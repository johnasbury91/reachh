---
phase: 01-foundation-security
plan: 03
type: execute
wave: 3
depends_on: ["01-02"]
files_modified:
  - dolphin/tracker.py
autonomous: true

must_haves:
  truths:
    - "Running `python tracker.py --test` produces output with username, karma, status, and freelancer columns"
    - "Request timing is visibly randomized (varies between 2-5 seconds between accounts)"
    - "Rate limit (429) triggers backoff message and continues without crashing"
    - "No credentials appear in tracker.py source code"
  artifacts:
    - path: "dolphin/tracker.py"
      provides: "Main orchestrator using async modules"
      contains: "async def run_tracker"
      min_lines: 100
  key_links:
    - from: "dolphin/tracker.py"
      to: "dolphin/sources/dolphin.py"
      via: "DolphinClient import and usage"
      pattern: "from sources import DolphinClient"
    - from: "dolphin/tracker.py"
      to: "dolphin/sources/reddit.py"
      via: "RedditChecker import and usage"
      pattern: "from sources import RedditChecker"
    - from: "dolphin/tracker.py"
      to: "dolphin/models.py"
      via: "data model imports"
      pattern: "from models import"
---

<objective>
Integrate new async modules into tracker.py and verify end-to-end functionality.

Purpose: Replace inline API calls in tracker.py with the modular DolphinClient and RedditChecker created in Plan 02. This completes the Phase 1 refactoring and validates all requirements.

Output:
- Refactored `tracker.py` using async/await with new modules
- End-to-end verification that all Phase 1 requirements are satisfied
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation-security/01-RESEARCH.md
@.planning/phases/01-foundation-security/01-01-SUMMARY.md
@.planning/phases/01-foundation-security/01-02-SUMMARY.md

# Files to modify
@dolphin/tracker.py
@dolphin/sources/dolphin.py
@dolphin/sources/reddit.py
@dolphin/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Refactor tracker.py to use async modules</name>
  <files>dolphin/tracker.py</files>
  <action>
Refactor `dolphin/tracker.py` to use the new async modules:

1. Update imports:
   - Remove: `from config import DOLPHIN_API_KEY, DOLPHIN_API_URL`
   - Remove: `import requests`
   - Add: `import asyncio`
   - Add: `from sources import DolphinClient, RedditChecker`
   - Add: `from models import DolphinProfile, RedditStatus, AccountResult`

2. Remove old functions (replaced by modules):
   - `get_team_users()` (now in DolphinClient)
   - `get_dolphin_profiles()` (now in DolphinClient)
   - `get_reddit_karma()` (now in RedditChecker)

3. Keep existing functions:
   - `categorize_account()` - still needed for categorization logic
   - `load_history()` - still needed for karma tracking
   - `save_history()` - still needed for karma tracking

4. Rewrite `run_tracker()` as async:
   ```python
   async def run_tracker(limit=None):
       """Main tracking function. Pass limit to only check first N profiles."""
       print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Starting tracker...")

       # Fetch Dolphin profiles
       print("Fetching Dolphin profiles...")
       async with DolphinClient() as dolphin:
           profiles = await dolphin.get_profiles()
       print(f"Found {len(profiles)} profiles")

       if limit:
           profiles = profiles[:limit]
           print(f"Test mode: checking only first {limit} profiles")

       # Load history
       history = load_history()
       today = datetime.now().strftime("%Y-%m-%d")

       # Check Reddit status for each profile
       results = []
       async with RedditChecker() as reddit:
           for i, profile in enumerate(profiles):
               print(f"[{i+1}/{len(profiles)}] Checking {profile.name}...", end=" ", flush=True)

               status = await reddit.check_account(profile.name)

               # Process result (karma tracking, categorization)
               # ... (preserve existing logic from run_tracker)

               results.append(result)

       # Save history and export CSV (preserve existing logic)
       # ...

       return results
   ```

5. Update main block:
   ```python
   if __name__ == "__main__":
       import sys
       test_mode = "--test" in sys.argv
       asyncio.run(run_tracker(limit=5 if test_mode else None))
   ```

PRESERVE:
- CSV export logic
- Karma history tracking
- Summary printing (by category, by owner)
- `categorize_account()` logic

REMOVE:
- `REDDIT_DELAY = 3` constant (delays now in settings)
- `REDDIT_RETRY_DELAY = 60` constant (backoff now in RedditChecker)
- All `time.sleep()` calls (replaced by async delays in RedditChecker)

The refactored tracker should produce identical CSV output to the original.
  </action>
  <verify>
- `grep -c "requests" dolphin/tracker.py` returns 0 (no sync requests)
- `grep -c "time.sleep" dolphin/tracker.py` returns 0 (no sync sleep)
- `grep -c "DolphinClient" dolphin/tracker.py` returns at least 1
- `grep -c "RedditChecker" dolphin/tracker.py` returns at least 1
- `grep -c "async def" dolphin/tracker.py` returns at least 1
  </verify>
  <done>tracker.py uses async modules, no sync HTTP or sleep calls</done>
</task>

<task type="auto">
  <name>Task 2: End-to-end verification</name>
  <files>None (verification only)</files>
  <action>
Run comprehensive verification of all Phase 1 requirements:

1. INFRA-01 (Credentials in .env):
   - `grep -c "eyJ0" dolphin/tracker.py` returns 0
   - `grep -c "eyJ0" dolphin/config.py` returns 0
   - `cat dolphin/.env | head -1` shows DOLPHIN_API_KEY exists

2. INFRA-02 (Randomized delays):
   - `grep -c "random.uniform" dolphin/sources/reddit.py` returns >= 2
   - Run tracker and observe timing varies between accounts

3. INFRA-03 (Rate limit handling):
   - `grep -c "429" dolphin/sources/reddit.py` returns >= 1
   - `grep -c "backoff" dolphin/sources/reddit.py` returns >= 1

4. CORE-01 (Pull profiles from Dolphin):
   - Run `python tracker.py --test` and verify profiles are fetched

5. CORE-02 (Reddit karma):
   - Output shows total_karma, comment_karma, link_karma columns

6. CORE-03 (Account status):
   - Output shows status column (active, suspended, not_found)

7. CORE-05 (Freelancer owner):
   - Output shows owner column with freelancer names

8. End-to-end test:
   ```bash
   cd dolphin && python tracker.py --test
   ```
   Should complete without errors and produce:
   - Console output with karma values
   - CSV file with all expected columns
  </action>
  <verify>
- `cd dolphin && python tracker.py --test` completes without errors
- `ls dolphin/tracking_*.csv` shows new CSV file created
- CSV contains columns: reddit_username, owner, total_karma, comment_karma, link_karma, reddit_status
  </verify>
  <done>All Phase 1 requirements verified working</done>
</task>

<task type="auto">
  <name>Task 3: Commit Phase 1 completion</name>
  <files>None (git operations only)</files>
  <action>
Commit all Phase 1 changes:

1. Stage all modified files:
   - dolphin/sources/__init__.py
   - dolphin/sources/dolphin.py
   - dolphin/sources/reddit.py
   - dolphin/models.py
   - dolphin/tracker.py

2. Commit with message:
   ```
   feat(dolphin): complete Phase 1 foundation and security

   - INFRA-01: Credentials moved to .env (Plan 01)
   - INFRA-02: Randomized request delays (2-5s)
   - INFRA-03: Rate limit handling with exponential backoff
   - CORE-01: Dolphin API client for profile fetching
   - CORE-02: Reddit karma tracking (total/comment/link)
   - CORE-03: Account status detection (active/suspended/not_found)
   - CORE-05: Freelancer owner tracking

   Refactored to async architecture using httpx and pydantic-settings.
   ```

3. Verify clean working tree:
   - `git status` shows no uncommitted changes (except .env which is ignored)
  </action>
  <verify>
- `git log -1 --oneline` shows the new commit
- `git status` shows clean working tree (only ignored files)
  </verify>
  <done>Phase 1 changes committed to git</done>
</task>

</tasks>

<verification>
Run the following checks to verify Phase 1 is complete:

```bash
# 1. Security - No credentials in code
grep -r "eyJ0" dolphin/*.py dolphin/sources/*.py && echo "FAIL" || echo "PASS: No JWT in code"

# 2. Anti-detection - Random delays
grep -c "random.uniform" dolphin/sources/reddit.py  # Should be >= 2

# 3. Rate limiting - Backoff handling
grep "429" dolphin/sources/reddit.py  # Should show 429 handling

# 4. End-to-end test
cd dolphin && python tracker.py --test

# 5. Verify CSV output columns
head -1 dolphin/tracking_*.csv | tr ',' '\n' | grep -E "(owner|total_karma|reddit_status)"
```
</verification>

<success_criteria>
1. `python tracker.py --test` produces account data (username, karma, status, freelancer)
2. No hardcoded credentials in any .py file
3. Request delays are randomized (2-5 seconds, visible in output timing)
4. Rate limits trigger backoff (not crashes)
5. CSV output includes: reddit_username, owner, total_karma, comment_karma, link_karma, reddit_status
6. All changes committed to git
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-security/01-03-SUMMARY.md`
</output>

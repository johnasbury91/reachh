---
phase: 01-foundation-security
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - dolphin/sources/__init__.py
  - dolphin/sources/dolphin.py
  - dolphin/sources/reddit.py
  - dolphin/models.py
autonomous: true

must_haves:
  truths:
    - "DolphinClient fetches all browser profiles with owner (freelancer) information"
    - "RedditChecker returns karma (total, comment, link) and status (active, suspended, not_found)"
    - "Request delays are randomized between 2-5 seconds (not fixed intervals)"
    - "Rate limits (429) trigger exponential backoff with jitter"
  artifacts:
    - path: "dolphin/sources/dolphin.py"
      provides: "Dolphin Anty API client"
      contains: "class DolphinClient"
      exports: ["DolphinClient", "DolphinProfile"]
    - path: "dolphin/sources/reddit.py"
      provides: "Reddit checker with anti-detection"
      contains: "class RedditChecker"
      exports: ["RedditChecker", "RedditStatus"]
    - path: "dolphin/models.py"
      provides: "Shared data models"
      contains: "class AccountResult"
    - path: "dolphin/sources/__init__.py"
      provides: "Package exports"
      exports: ["DolphinClient", "RedditChecker"]
  key_links:
    - from: "dolphin/sources/dolphin.py"
      to: "dolphin/config.py"
      via: "settings import"
      pattern: "from.*config import settings"
    - from: "dolphin/sources/reddit.py"
      to: "dolphin/config.py"
      via: "settings import for delays"
      pattern: "settings\\.reddit_(min|max)_delay"
    - from: "dolphin/sources/reddit.py"
      to: "random.uniform"
      via: "randomized delays"
      pattern: "random\\.uniform.*settings\\.reddit"
---

<objective>
Create modular API clients for Dolphin Anty and Reddit with built-in anti-detection patterns.

Purpose: Replace inline API calls in tracker.py with reusable async clients. Reddit checker includes randomized delays and exponential backoff to satisfy INFRA-02 and INFRA-03.

Output:
- `sources/dolphin.py` - Async client for Dolphin Anty API (profiles, team users)
- `sources/reddit.py` - Async Reddit checker with anti-detection (random delays, rate limit backoff)
- `models.py` - Shared data models (DolphinProfile, RedditStatus, AccountResult)
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation-security/01-RESEARCH.md
@.planning/phases/01-foundation-security/01-01-SUMMARY.md

# Existing code patterns to preserve
@dolphin/tracker.py
@dolphin/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create data models</name>
  <files>dolphin/models.py</files>
  <action>
Create `dolphin/models.py` with Pydantic/dataclass models:

1. `DolphinProfile` dataclass:
   - id: str
   - name: str (this is the Reddit username)
   - owner: str (freelancer who owns this account)
   - notes: str
   - created_at: str
   - updated_at: str

2. `RedditStatus` dataclass:
   - username: str
   - status: Literal["active", "suspended", "not_found", "rate_limited", "error"]
   - total_karma: int = 0
   - comment_karma: int = 0
   - link_karma: int = 0
   - created_utc: float = 0
   - error_message: str | None = None

3. `AccountResult` dataclass (combined result for tracker output):
   - profile: DolphinProfile
   - reddit: RedditStatus
   - category: str
   - karma_change: int = 0
   - checked_at: str

Use dataclasses (not Pydantic models) for simplicity - these are just data containers.
  </action>
  <verify>
- `python -c "from dolphin.models import DolphinProfile, RedditStatus, AccountResult; print('Models OK')"`
  </verify>
  <done>Data models defined and importable</done>
</task>

<task type="auto">
  <name>Task 2: Create Dolphin API client</name>
  <files>dolphin/sources/__init__.py, dolphin/sources/dolphin.py</files>
  <action>
1. Create `dolphin/sources/` directory if it doesn't exist

2. Create `dolphin/sources/__init__.py`:
   ```python
   from .dolphin import DolphinClient
   from .reddit import RedditChecker
   ```

3. Create `dolphin/sources/dolphin.py` following the pattern from 01-RESEARCH.md:

   - Use `httpx.AsyncClient` with context manager pattern
   - Import settings from config.py
   - Use `settings.dolphin_api_key.get_secret_value()` for Authorization header

   DolphinClient class with async context manager:
   - `__aenter__` / `__aexit__` for httpx client lifecycle
   - `get_team_users()` -> list[dict] (fetch team user IDs and names)
   - `get_profiles()` -> list[DolphinProfile] (fetch all profiles with pagination)
     - Build user_map for owner lookup
     - Paginate with limit=100
     - Map each profile to DolphinProfile dataclass
     - Include notes extraction logic from existing tracker.py

Preserve the existing API call patterns from tracker.py but use httpx instead of requests.
  </action>
  <verify>
- `python -c "from dolphin.sources import DolphinClient; print('DolphinClient OK')"`
- Test client (requires .env): `python -c "import asyncio; from dolphin.sources import DolphinClient; async def t(): async with DolphinClient() as c: users = await c.get_team_users(); print(f'Found {len(users)} users'); asyncio.run(t())"`
  </verify>
  <done>DolphinClient fetches team users and profiles via async httpx</done>
</task>

<task type="auto">
  <name>Task 3: Create Reddit checker with anti-detection</name>
  <files>dolphin/sources/reddit.py</files>
  <action>
Create `dolphin/sources/reddit.py` following the pattern from 01-RESEARCH.md "Reddit Checker with Rate Limit Handling":

RedditChecker class with async context manager:
- `__aenter__` / `__aexit__` for httpx client lifecycle
- User-Agent from settings.reddit_user_agent

Core methods:
1. `_random_delay()` -> None
   - Use `random.uniform(settings.reddit_min_delay, settings.reddit_max_delay)`
   - This is CRITICAL for INFRA-02 (randomized delays)

2. `check_account(username: str)` -> RedditStatus
   - URL: `https://www.reddit.com/user/{username}/about.json`
   - Retry loop up to settings.reddit_max_retries
   - Call `_random_delay()` before each request

   Status code handling:
   - 200: Parse JSON, return status="active" with karma values
   - 404: Return status="not_found"
   - 403: Return status="suspended"
   - 429: Rate limited - exponential backoff
     - Check Retry-After header first
     - Otherwise: `delay = settings.reddit_backoff_base * (2 ** attempt) + random.uniform(0, 1)`
     - Log the backoff: `print(f"Rate limited, backing off {delay:.1f}s...")`
     - Continue retry loop
   - Other: Return status="error" with HTTP code

   Exception handling:
   - Catch httpx.RequestError
   - Retry with backoff on network errors
   - Return status="error" with message on final failure

3. `check_accounts(usernames: list[str])` -> list[RedditStatus]
   - Iterate usernames, calling check_account for each
   - Returns list in same order

IMPORTANT:
- Import `random` module for delays
- All delays must use random.uniform, never fixed values
- This satisfies INFRA-02 (randomized delays) and INFRA-03 (rate limit handling)
  </action>
  <verify>
- `python -c "from dolphin.sources import RedditChecker; print('RedditChecker OK')"`
- `grep -c "random.uniform" dolphin/sources/reddit.py` returns at least 2 (delay + jitter)
- `grep -c "time.sleep" dolphin/sources/reddit.py` returns 0 (no sync sleep)
- Test: `python -c "import asyncio; from dolphin.sources import RedditChecker; async def t(): async with RedditChecker() as r: s = await r.check_account('spez'); print(s); asyncio.run(t())"`
  </verify>
  <done>RedditChecker with randomized delays and exponential backoff on rate limits</done>
</task>

</tasks>

<verification>
Run the following checks to verify Phase 1 Plan 02 is complete:

```bash
# 1. All modules import correctly
python -c "from dolphin.models import DolphinProfile, RedditStatus, AccountResult; print('Models OK')"
python -c "from dolphin.sources import DolphinClient, RedditChecker; print('Sources OK')"

# 2. Anti-detection patterns present
grep -c "random.uniform" dolphin/sources/reddit.py  # Should be >= 2
grep -c "asyncio.sleep" dolphin/sources/reddit.py  # Should be >= 1
grep -c "time.sleep" dolphin/sources/reddit.py     # Should be 0

# 3. Settings integration
grep "settings.reddit" dolphin/sources/reddit.py  # Should show delay settings

# 4. Live test (checks real account)
python -c "
import asyncio
from dolphin.sources import RedditChecker

async def test():
    async with RedditChecker() as checker:
        result = await checker.check_account('spez')
        print(f'Status: {result.status}')
        print(f'Total karma: {result.total_karma}')
        assert result.status == 'active', 'spez should be active'
        print('PASS')

asyncio.run(test())
"
```
</verification>

<success_criteria>
1. DolphinClient fetches profiles with owner (freelancer) information
2. RedditChecker returns karma breakdown (total, comment, link)
3. RedditChecker returns status (active, suspended, not_found)
4. Request delays use random.uniform (not fixed values)
5. 429 responses trigger exponential backoff with jitter
6. All modules are async-native using httpx
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-security/01-02-SUMMARY.md`
</output>
